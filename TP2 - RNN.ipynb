{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re    # for regular expressions \n",
    "import nltk  # for text manipulation \n",
    "from nltk.corpus import stopwords\n",
    "import string \n",
    "import warnings \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt  \n",
    "import xgboost as xgb\n",
    "from sklearn import tree\n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from sklearn.model_selection import GridSearchCV,StratifiedKFold,RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>long</th>\n",
       "      <th>equal_words</th>\n",
       "      <th>Tags</th>\n",
       "      <th>with_url</th>\n",
       "      <th>#words</th>\n",
       "      <th>#hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>unique_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>1</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      target  long  equal_words  Tags  with_url  #words  #hashtags  \\\n",
       "0          1    69            0     0         0      13          1   \n",
       "1          1    38            0     0         0       7          0   \n",
       "2          1   133            0     0         0      22          0   \n",
       "3          1    65            0     0         0       8          1   \n",
       "4          1    88            0     0         0      16          2   \n",
       "...      ...   ...          ...   ...       ...     ...        ...   \n",
       "7608       1    83            0     0         1      11          0   \n",
       "7609       1   125            0     2         0      20          0   \n",
       "7610       1    65            0     0         1       8          0   \n",
       "7611       1   137            0     0         0      19          0   \n",
       "7612       1    94            0     0         1      13          0   \n",
       "\n",
       "                                                   text  unique_words  \n",
       "0     Our Deeds are the Reason of this #earthquake M...            13  \n",
       "1                Forest fire near La Ronge Sask. Canada             7  \n",
       "2     All residents asked to 'shelter in place' are ...            20  \n",
       "3     13,000 people receive #wildfires evacuation or...             8  \n",
       "4     Just got sent this photo from Ruby #Alaska as ...            15  \n",
       "...                                                 ...           ...  \n",
       "7608  Two giant cranes holding a bridge collapse int...            11  \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...            16  \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...             8  \n",
       "7611  Police investigating after an e-bike collided ...            18  \n",
       "7612  The Latest: More Homes Razed by Northern Calif...            13  \n",
       "\n",
       "[7613 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain = pd.read_csv('train.csv')\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain['text'] = xtrain['text'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "xtrain['text'] = xtrain['text'].apply(lambda x: tokenizer.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    words = []\n",
    "    for w in text:\n",
    "        if w not in stopwords.words('english'):\n",
    "            words.append(w)\n",
    "    #words = [w for w in text if w not in stopwords.words('english')]\n",
    "    return words\n",
    "\n",
    "xtrain['text'] = xtrain['text'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_text(list_of_text):\n",
    "    combined_text = ' '.join(list_of_text)\n",
    "    return combined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain['text'] = xtrain['text'].apply(lambda x: combine_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['forest', 'fire', 'near', 'la', 'ronge', 'sask', 'canada']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_tweet = xtrain.text.apply(lambda x: x.split())\n",
    "tokenized_tweet[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_vector(tokens, size):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            vec += model_glovec[word].reshape((1, size))\n",
    "            count += 1.\n",
    "        except KeyError:  # handling the case where the token is not in vocabulary\n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_glovec = {}\n",
    "with open(\"glove.twitter.27B.200d.txt\", 'r', encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        model_glovec[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 200)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_arrays = np.zeros((len(tokenized_tweet), 200)) \n",
    "for i in range(len(tokenized_tweet)):\n",
    "    wordvec_arrays[i,:] = word_vector(tokenized_tweet[i], 200)\n",
    "wordvec_df = pd.DataFrame(wordvec_arrays)\n",
    "wordvec_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3263, 200)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest = pd.read_csv('test.csv')\n",
    "xtest.text = xtest.text.apply(lambda x: clean_text(x))\n",
    "xtest.text = xtest.text.apply(lambda x: tokenizer.tokenize(x))\n",
    "xtest.text = xtest.text.apply(lambda x: remove_stopwords(x))\n",
    "xtest.text = xtest.text.apply(lambda x: combine_text(x))\n",
    "tokenized_test = xtest.text.apply(lambda x: x.split()) # tokenizing \n",
    "wordvec_test = np.zeros((len(tokenized_test), 200)) \n",
    "for i in range(len(tokenized_test)):\n",
    "    wordvec_test[i,:] = word_vector(tokenized_test[i], 200)\n",
    "wordvect_df = pd.DataFrame(wordvec_test)\n",
    "wordvect_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_gv = wordvec_df\n",
    "xtest_gv = wordvect_df\n",
    "ytrain= xtrain.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_gv = np.asarray(xtrain_gv).reshape(-1,1,200)\n",
    "xtest_gv = np.asarray(xtest_gv).reshape(-1,1,200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(xtrain_gv, \n",
    "                                                    ytrain, \n",
    "                                                    test_size=0.25, random_state=42, \n",
    "                                                    stratify=ytrain\n",
    "                                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5709"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_10 (Bidirectio (6090, 1, 150)            429600    \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (6090, 1, 70)             10570     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (6090, 1, 70)             0         \n",
      "_________________________________________________________________\n",
      "bidirectional_11 (Bidirectio (6090, 1, 70)             78960     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_5 (Glob (6090, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (6090, 120)               8520      \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (6090, 120)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (6090, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (6090, 30)                3630      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (6090, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 531,311\n",
      "Trainable params: 531,311\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, GlobalMaxPooling1D, Dropout, Activation, Bidirectional, Embedding, GRU,RNN\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(200,input_shape=(1,207), return_sequences=True, recurrent_dropout=0.1), merge_mode=\"mul\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Bidirectional(LSTM(300,input_shape=(1,207), return_sequences=True,recurrent_dropout=0.1),merge_mode=\"ave\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(150))\n",
    "model.add((LSTM(100,input_shape=(1,207), return_sequences=True,recurrent_dropout=0.1)))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(450))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.build(input_shape=(6090,1,200))\n",
    "model.summary()\n",
    "opt = keras.optimizers.Adam(learning_rate=0.00005)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.22043065e-03,  2.44429858e-01, -7.32538583e-02, ...,\n",
       "          1.30000000e+01,  1.00000000e+00,  1.30000000e+01]],\n",
       "\n",
       "       [[-2.20747002e-01,  2.34415733e-02, -8.55718340e-04, ...,\n",
       "          7.00000000e+00,  0.00000000e+00,  7.00000000e+00]],\n",
       "\n",
       "       [[-2.78436369e-02,  1.26615633e-01, -3.20697912e-01, ...,\n",
       "          2.20000000e+01,  0.00000000e+00,  2.00000000e+01]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-1.03846498e-01, -1.79474987e-01,  6.76399991e-02, ...,\n",
       "          8.00000000e+00,  0.00000000e+00,  8.00000000e+00]],\n",
       "\n",
       "       [[-1.01647925e-01, -1.73949861e-01, -2.21665574e-01, ...,\n",
       "          1.90000000e+01,  0.00000000e+00,  1.80000000e+01]],\n",
       "\n",
       "       [[-1.66893874e-01,  7.66258766e-02, -3.97220122e-01, ...,\n",
       "          1.30000000e+01,  0.00000000e+00,  1.30000000e+01]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_review_length = 200 \n",
    "x_train = np.asarray(xtrain_gv)\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "#X_train = pad_sequences(x_train, maxlen=max_review_length)\n",
    "x_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4296597924602653"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Y_train = np.asarray(ytrain)\n",
    "Y_train.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "54/54 [==============================] - 2s 44ms/step - loss: 0.6902 - accuracy: 0.5587 - val_loss: 0.6869 - val_accuracy: 0.5700\n",
      "Epoch 2/40\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.6846 - accuracy: 0.5704 - val_loss: 0.6810 - val_accuracy: 0.5700\n",
      "Epoch 3/40\n",
      "54/54 [==============================] - 1s 24ms/step - loss: 0.6788 - accuracy: 0.5704 - val_loss: 0.6728 - val_accuracy: 0.5700\n",
      "Epoch 4/40\n",
      "54/54 [==============================] - 1s 24ms/step - loss: 0.6690 - accuracy: 0.5711 - val_loss: 0.6586 - val_accuracy: 0.5707\n",
      "Epoch 5/40\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.6513 - accuracy: 0.5966 - val_loss: 0.6325 - val_accuracy: 0.6303\n",
      "Epoch 6/40\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.6249 - accuracy: 0.6692 - val_loss: 0.5962 - val_accuracy: 0.6961\n",
      "Epoch 7/40\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.5951 - accuracy: 0.6975 - val_loss: 0.5657 - val_accuracy: 0.7136\n",
      "Epoch 8/40\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.5704 - accuracy: 0.7202 - val_loss: 0.5422 - val_accuracy: 0.7255\n",
      "Epoch 9/40\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.5524 - accuracy: 0.7332 - val_loss: 0.5220 - val_accuracy: 0.7388\n",
      "Epoch 10/40\n",
      "54/54 [==============================] - 1s 24ms/step - loss: 0.5306 - accuracy: 0.7468 - val_loss: 0.5033 - val_accuracy: 0.7577\n",
      "Epoch 11/40\n",
      "54/54 [==============================] - 1s 24ms/step - loss: 0.5111 - accuracy: 0.7615 - val_loss: 0.4806 - val_accuracy: 0.7668\n",
      "Epoch 12/40\n",
      "54/54 [==============================] - 1s 24ms/step - loss: 0.4913 - accuracy: 0.7737 - val_loss: 0.4635 - val_accuracy: 0.7766\n",
      "Epoch 13/40\n",
      "54/54 [==============================] - 1s 24ms/step - loss: 0.4760 - accuracy: 0.7830 - val_loss: 0.4471 - val_accuracy: 0.7878\n",
      "Epoch 14/40\n",
      "54/54 [==============================] - 1s 24ms/step - loss: 0.4640 - accuracy: 0.7877 - val_loss: 0.4381 - val_accuracy: 0.7934\n",
      "Epoch 15/40\n",
      "54/54 [==============================] - 1s 24ms/step - loss: 0.4564 - accuracy: 0.7909 - val_loss: 0.4332 - val_accuracy: 0.7941\n",
      "Epoch 16/40\n",
      "54/54 [==============================] - 1s 24ms/step - loss: 0.4516 - accuracy: 0.7989 - val_loss: 0.4299 - val_accuracy: 0.7976\n",
      "Epoch 17/40\n",
      "54/54 [==============================] - 1s 24ms/step - loss: 0.4543 - accuracy: 0.7956 - val_loss: 0.4304 - val_accuracy: 0.7990\n",
      "Epoch 18/40\n",
      "54/54 [==============================] - 1s 24ms/step - loss: 0.4460 - accuracy: 0.7975 - val_loss: 0.4285 - val_accuracy: 0.8004\n",
      "Epoch 19/40\n",
      "54/54 [==============================] - 1s 25ms/step - loss: 0.4437 - accuracy: 0.7998 - val_loss: 0.4263 - val_accuracy: 0.7997\n",
      "Epoch 20/40\n",
      "54/54 [==============================] - 1s 24ms/step - loss: 0.4449 - accuracy: 0.8010 - val_loss: 0.4249 - val_accuracy: 0.7990\n",
      "Epoch 21/40\n",
      "54/54 [==============================] - 1s 25ms/step - loss: 0.4392 - accuracy: 0.8047 - val_loss: 0.4264 - val_accuracy: 0.8088\n",
      "Epoch 22/40\n",
      "54/54 [==============================] - 1s 25ms/step - loss: 0.4419 - accuracy: 0.8019 - val_loss: 0.4244 - val_accuracy: 0.8095\n",
      "Epoch 23/40\n",
      "54/54 [==============================] - 1s 25ms/step - loss: 0.4399 - accuracy: 0.8026 - val_loss: 0.4229 - val_accuracy: 0.8011\n",
      "Epoch 24/40\n",
      "54/54 [==============================] - 1s 26ms/step - loss: 0.4378 - accuracy: 0.8073 - val_loss: 0.4316 - val_accuracy: 0.7983\n",
      "Epoch 25/40\n",
      "54/54 [==============================] - 1s 26ms/step - loss: 0.4371 - accuracy: 0.8115 - val_loss: 0.4218 - val_accuracy: 0.8074\n",
      "Epoch 26/40\n",
      "54/54 [==============================] - 1s 27ms/step - loss: 0.4343 - accuracy: 0.8103 - val_loss: 0.4217 - val_accuracy: 0.8123\n",
      "Epoch 27/40\n",
      "54/54 [==============================] - 1s 24ms/step - loss: 0.4323 - accuracy: 0.8094 - val_loss: 0.4215 - val_accuracy: 0.8123\n",
      "Epoch 28/40\n",
      "54/54 [==============================] - 1s 25ms/step - loss: 0.4309 - accuracy: 0.8080 - val_loss: 0.4207 - val_accuracy: 0.8060\n",
      "Epoch 29/40\n",
      "54/54 [==============================] - 1s 24ms/step - loss: 0.4306 - accuracy: 0.8092 - val_loss: 0.4219 - val_accuracy: 0.7997\n",
      "Epoch 30/40\n",
      "54/54 [==============================] - 1s 25ms/step - loss: 0.4340 - accuracy: 0.8050 - val_loss: 0.4222 - val_accuracy: 0.8151\n",
      "Epoch 31/40\n",
      "54/54 [==============================] - 1s 27ms/step - loss: 0.4266 - accuracy: 0.8080 - val_loss: 0.4201 - val_accuracy: 0.8109\n",
      "Epoch 32/40\n",
      "54/54 [==============================] - 1s 27ms/step - loss: 0.4261 - accuracy: 0.8078 - val_loss: 0.4198 - val_accuracy: 0.8081\n",
      "Epoch 33/40\n",
      "54/54 [==============================] - 1s 25ms/step - loss: 0.4277 - accuracy: 0.8071 - val_loss: 0.4235 - val_accuracy: 0.8109\n",
      "Epoch 34/40\n",
      "54/54 [==============================] - 1s 24ms/step - loss: 0.4265 - accuracy: 0.8089 - val_loss: 0.4227 - val_accuracy: 0.7997\n",
      "Epoch 35/40\n",
      "54/54 [==============================] - 1s 24ms/step - loss: 0.4238 - accuracy: 0.8092 - val_loss: 0.4196 - val_accuracy: 0.8102\n",
      "Epoch 36/40\n",
      "54/54 [==============================] - 1s 25ms/step - loss: 0.4233 - accuracy: 0.8157 - val_loss: 0.4202 - val_accuracy: 0.8060\n",
      "Epoch 37/40\n",
      "54/54 [==============================] - 1s 24ms/step - loss: 0.4240 - accuracy: 0.8136 - val_loss: 0.4209 - val_accuracy: 0.8088\n",
      "Epoch 38/40\n",
      "54/54 [==============================] - 1s 25ms/step - loss: 0.4202 - accuracy: 0.8150 - val_loss: 0.4203 - val_accuracy: 0.8067\n",
      "Epoch 39/40\n",
      "54/54 [==============================] - 1s 24ms/step - loss: 0.4227 - accuracy: 0.8159 - val_loss: 0.4229 - val_accuracy: 0.8081\n",
      "Epoch 40/40\n",
      "54/54 [==============================] - 1s 27ms/step - loss: 0.4186 - accuracy: 0.8164 - val_loss: 0.4204 - val_accuracy: 0.8088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20e240c4fd0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test training\n",
    "model.fit(X_train, y_train, validation_split=0.25, epochs =40, batch_size=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "115/115 [==============================] - 4s 32ms/step - loss: 0.6885 - accuracy: 0.5696 - val_loss: 0.6876 - val_accuracy: 0.5494\n",
      "Epoch 2/35\n",
      "115/115 [==============================] - 2s 20ms/step - loss: 0.6798 - accuracy: 0.5773 - val_loss: 0.6795 - val_accuracy: 0.5494\n",
      "Epoch 3/35\n",
      "115/115 [==============================] - 2s 21ms/step - loss: 0.6623 - accuracy: 0.5775 - val_loss: 0.6437 - val_accuracy: 0.5494\n",
      "Epoch 4/35\n",
      "115/115 [==============================] - 2s 20ms/step - loss: 0.6162 - accuracy: 0.6537 - val_loss: 0.5734 - val_accuracy: 0.7306\n",
      "Epoch 5/35\n",
      "115/115 [==============================] - 2s 20ms/step - loss: 0.5708 - accuracy: 0.7145 - val_loss: 0.5317 - val_accuracy: 0.7489\n",
      "Epoch 6/35\n",
      "115/115 [==============================] - 2s 21ms/step - loss: 0.5386 - accuracy: 0.7446 - val_loss: 0.4969 - val_accuracy: 0.7673\n",
      "Epoch 7/35\n",
      "115/115 [==============================] - 2s 21ms/step - loss: 0.5066 - accuracy: 0.7705 - val_loss: 0.4661 - val_accuracy: 0.7826\n",
      "Epoch 8/35\n",
      "115/115 [==============================] - 2s 21ms/step - loss: 0.4760 - accuracy: 0.7863 - val_loss: 0.4412 - val_accuracy: 0.7936\n",
      "Epoch 9/35\n",
      "115/115 [==============================] - 2s 21ms/step - loss: 0.4676 - accuracy: 0.7921 - val_loss: 0.4309 - val_accuracy: 0.7910\n",
      "Epoch 10/35\n",
      "115/115 [==============================] - 2s 21ms/step - loss: 0.4585 - accuracy: 0.7944 - val_loss: 0.4324 - val_accuracy: 0.7994\n",
      "Epoch 11/35\n",
      "115/115 [==============================] - 3s 22ms/step - loss: 0.4548 - accuracy: 0.7958 - val_loss: 0.4252 - val_accuracy: 0.7952\n",
      "Epoch 12/35\n",
      "115/115 [==============================] - 3s 23ms/step - loss: 0.4481 - accuracy: 0.7977 - val_loss: 0.4228 - val_accuracy: 0.7936\n",
      "Epoch 13/35\n",
      "115/115 [==============================] - 2s 22ms/step - loss: 0.4475 - accuracy: 0.8007 - val_loss: 0.4233 - val_accuracy: 0.7978\n",
      "Epoch 14/35\n",
      "115/115 [==============================] - 2s 21ms/step - loss: 0.4438 - accuracy: 0.7980 - val_loss: 0.4212 - val_accuracy: 0.7973\n",
      "Epoch 15/35\n",
      "115/115 [==============================] - 2s 22ms/step - loss: 0.4401 - accuracy: 0.8026 - val_loss: 0.4238 - val_accuracy: 0.7994\n",
      "Epoch 16/35\n",
      "115/115 [==============================] - 2s 21ms/step - loss: 0.4405 - accuracy: 0.8036 - val_loss: 0.4197 - val_accuracy: 0.7957\n",
      "Epoch 17/35\n",
      "115/115 [==============================] - 2s 21ms/step - loss: 0.4369 - accuracy: 0.8035 - val_loss: 0.4208 - val_accuracy: 0.7983\n",
      "Epoch 18/35\n",
      "115/115 [==============================] - 2s 21ms/step - loss: 0.4360 - accuracy: 0.8066 - val_loss: 0.4194 - val_accuracy: 0.8088\n",
      "Epoch 19/35\n",
      "115/115 [==============================] - 2s 22ms/step - loss: 0.4356 - accuracy: 0.8068 - val_loss: 0.4200 - val_accuracy: 0.7988\n",
      "Epoch 20/35\n",
      "115/115 [==============================] - 3s 22ms/step - loss: 0.4336 - accuracy: 0.8071 - val_loss: 0.4196 - val_accuracy: 0.8078\n",
      "Epoch 21/35\n",
      "115/115 [==============================] - 2s 21ms/step - loss: 0.4340 - accuracy: 0.8042 - val_loss: 0.4206 - val_accuracy: 0.8009\n",
      "Epoch 22/35\n",
      "115/115 [==============================] - 2s 21ms/step - loss: 0.4306 - accuracy: 0.8068 - val_loss: 0.4232 - val_accuracy: 0.7988\n",
      "Epoch 23/35\n",
      "115/115 [==============================] - 2s 21ms/step - loss: 0.4256 - accuracy: 0.8091 - val_loss: 0.4195 - val_accuracy: 0.7967\n",
      "Epoch 24/35\n",
      "115/115 [==============================] - 2s 21ms/step - loss: 0.4287 - accuracy: 0.8103 - val_loss: 0.4197 - val_accuracy: 0.7978\n",
      "Epoch 25/35\n",
      "115/115 [==============================] - 2s 21ms/step - loss: 0.4270 - accuracy: 0.8108 - val_loss: 0.4201 - val_accuracy: 0.7952\n",
      "Epoch 26/35\n",
      "115/115 [==============================] - 2s 21ms/step - loss: 0.4215 - accuracy: 0.8119 - val_loss: 0.4245 - val_accuracy: 0.7978\n",
      "Epoch 27/35\n",
      "115/115 [==============================] - 3s 22ms/step - loss: 0.4206 - accuracy: 0.8121 - val_loss: 0.4246 - val_accuracy: 0.7973\n",
      "Epoch 28/35\n",
      "115/115 [==============================] - 2s 22ms/step - loss: 0.4218 - accuracy: 0.8136 - val_loss: 0.4225 - val_accuracy: 0.8020\n",
      "Epoch 29/35\n",
      "115/115 [==============================] - 3s 22ms/step - loss: 0.4186 - accuracy: 0.8131 - val_loss: 0.4236 - val_accuracy: 0.7994\n",
      "Epoch 30/35\n",
      "115/115 [==============================] - 2s 22ms/step - loss: 0.4185 - accuracy: 0.8136 - val_loss: 0.4271 - val_accuracy: 0.7983\n",
      "Epoch 31/35\n",
      "115/115 [==============================] - 2s 21ms/step - loss: 0.4185 - accuracy: 0.8150 - val_loss: 0.4259 - val_accuracy: 0.7967\n",
      "Epoch 32/35\n",
      "115/115 [==============================] - 2s 21ms/step - loss: 0.4204 - accuracy: 0.8157 - val_loss: 0.4266 - val_accuracy: 0.7994\n",
      "Epoch 33/35\n",
      "115/115 [==============================] - 3s 23ms/step - loss: 0.4165 - accuracy: 0.8157 - val_loss: 0.4249 - val_accuracy: 0.8030\n",
      "Epoch 34/35\n",
      "115/115 [==============================] - 3s 23ms/step - loss: 0.4157 - accuracy: 0.8175 - val_loss: 0.4242 - val_accuracy: 0.8051\n",
      "Epoch 35/35\n",
      "115/115 [==============================] - 3s 23ms/step - loss: 0.4131 - accuracy: 0.8191 - val_loss: 0.4271 - val_accuracy: 0.7973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20e338ba358>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamiento completo\n",
    "x_train = np.asarray(xtrain_gv)\n",
    "model.fit(x_train, ytrain, validation_split=0.25, epochs =35, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hago tests internos\n",
    "tests=model.predict(X_test)\n",
    "type(tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test = pd.DataFrame(y_test)\n",
    "#y_test=y_test.drop(columns='index', inplace=True)\n",
    "y_test = pd.DataFrame(y_test.reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.drop(columns='index', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test      0.373424\n",
       "target    0.429622\n",
       "diff      0.816702\n",
       "dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score_df=pd.DataFrame(columns=['test', 'target'])\n",
    "score_data= pd.DataFrame(tests)\n",
    "score_data.rename(columns={0:'test'}, inplace=True)\n",
    "score_data.test=score_data.test.apply(lambda x: int(round(x)))\n",
    "score_data['target']= y_test['target']\n",
    "score_data['diff']=score_data[['test', 'target']].apply(lambda x: 1 if int((x.test).round()) == x.target else 0, axis=1)\n",
    "score_data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=model.predict(xtest_gv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids=[]\n",
    "with open(\"sample_submission.csv\", 'r') as f:\n",
    "    for line in f:\n",
    "        vals = line.split(',')\n",
    "        if vals[0]!='id':\n",
    "            ids.append(int(vals[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "en = open(\"submission.csv\", 'w')\n",
    "n=0\n",
    "en.write(\"id,target\\n\")\n",
    "for i in ids:\n",
    "    en.write(str(i) +','+ str(int((A[n].round())))+'\\n')\n",
    "    \n",
    "    n+=1\n",
    "en.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrnn=pd.read_csv(\"submissiona.csv\")\n",
    "dfrnn['xgb']=A\n",
    "dfrnn['diffe']=abs(dfrnn['xgb']-dfrnn['target'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrnn.diffe.apply('sum')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
